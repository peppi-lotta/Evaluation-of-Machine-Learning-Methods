{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 | TKO_7092 Evaluation of Machine Learning Methods 2023\n",
    "## deadline: 15.2.2023 - 23:59\n",
    "\n",
    "Regarding any questions about this exercise, please contact course assistant Jonne Pohjankukka (jjepoh@utu.fi)\n",
    "\n",
    "********************************************\n",
    "\n",
    "Student name: Peppi-Lotta Saari\n",
    "\n",
    "Student number: 517334\n",
    "\n",
    "Student email: plsaar@utu.fi\n",
    "\n",
    "********************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water permeability prediction in forestry <br>\n",
    "\n",
    "In this task, the client wants you to estimate the spatial prediction performance of K-nearest neighbor regression model with K=5 (5NN), using spatial leave-one-out cross-validation (i.e. SKCV, with number of folds == number of data points). The client wants you to use the C-index as the performance measure.  \n",
    "\n",
    "In other words, the client wants you to answer the question: \"What happens to the prediction performance of water permeability using 5-nearest neighbor regression model, when the geographical distance between known data and unknown data increases?\".\n",
    "\n",
    "In this task, you have three data files available (with 1691 data points): \n",
    "\n",
    "- input.csv, contains the 75 predictor features. \n",
    "- output.csv, contains the water permebility values. \n",
    "- coordinates.csv, contains the corresponding geographical coordinate locations of the data points. The unit of the coordinates is metre, and you can use Euclidean distance to calculate distances between the coordinate points. \n",
    "\n",
    "Implement the following tasks to complete this exercise:\n",
    "\n",
    "********************************************\n",
    "\n",
    "#### 1. Z-score standardize the predictor features (input.csv). \n",
    "\n",
    "#### 2. Perform spatial leave-one-out cross-validation with 5NN model for the provided data set (refer to the lectures 3.1.3 and 3.1.4 for help). Estimate the water permeability prediction performance (using 5NN model and C-index) with the following distance parameter values: d = 0, 10, 20, ..., 250 (that is, 10 meter intervals from 0m to 250m). \n",
    "\n",
    "#### 3. When you have calculated the C-index performance measure for each value of d, visualize the results with the C-index (y-axis) as a function of d (x-axis).\n",
    "\n",
    "********************************************\n",
    "\n",
    "Your .ipynb-file must include the following: \n",
    "\n",
    "- Your own implementation of the spatial leave-one-out cross-validation for the current task. Remember to also take advantage of earlier exercises (e.g. C-index). For the 5-nearest neighbor and Euclidean distance calculation you can use third-party libraries (e.g. Scikit-learn) if you want. Also, try to follow good programming practices and add comments to relevant parts of your code explaining what you are doing and why.\n",
    "\n",
    "\n",
    "- Plot of the graph C-index vs. distance parameter value. \n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "-- START IMPLEMENTING YOUR EXERCISE AFTER THIS LINE --\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, import all the libraries that you need. For example: \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import math\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.053196</td>\n",
       "      <td>-0.219296</td>\n",
       "      <td>0.210020</td>\n",
       "      <td>0.704425</td>\n",
       "      <td>0.339477</td>\n",
       "      <td>0.412638</td>\n",
       "      <td>0.331074</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.184481</td>\n",
       "      <td>0.307345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219541</td>\n",
       "      <td>0.539119</td>\n",
       "      <td>-0.645254</td>\n",
       "      <td>-0.519918</td>\n",
       "      <td>-0.447089</td>\n",
       "      <td>0.554097</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>-0.109193</td>\n",
       "      <td>-0.913639</td>\n",
       "      <td>-0.461479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.632098</td>\n",
       "      <td>-0.682804</td>\n",
       "      <td>-0.285522</td>\n",
       "      <td>-0.369542</td>\n",
       "      <td>-0.138305</td>\n",
       "      <td>2.489725</td>\n",
       "      <td>2.051755</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.246906</td>\n",
       "      <td>-0.226797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219541</td>\n",
       "      <td>-0.169259</td>\n",
       "      <td>-0.645254</td>\n",
       "      <td>2.475438</td>\n",
       "      <td>-0.447089</td>\n",
       "      <td>-0.288927</td>\n",
       "      <td>-0.035919</td>\n",
       "      <td>-1.481978</td>\n",
       "      <td>-1.087664</td>\n",
       "      <td>-0.461479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.674980</td>\n",
       "      <td>-0.597421</td>\n",
       "      <td>-0.568689</td>\n",
       "      <td>-0.983237</td>\n",
       "      <td>-0.828435</td>\n",
       "      <td>-0.496087</td>\n",
       "      <td>-0.451053</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.324938</td>\n",
       "      <td>-0.627405</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047724</td>\n",
       "      <td>-0.877636</td>\n",
       "      <td>-0.645254</td>\n",
       "      <td>-0.519918</td>\n",
       "      <td>-0.447089</td>\n",
       "      <td>-0.375320</td>\n",
       "      <td>-0.159124</td>\n",
       "      <td>0.349947</td>\n",
       "      <td>0.134707</td>\n",
       "      <td>-0.809315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.331927</td>\n",
       "      <td>-0.154649</td>\n",
       "      <td>1.307292</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.419107</td>\n",
       "      <td>1.061728</td>\n",
       "      <td>0.956776</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.301529</td>\n",
       "      <td>-0.360333</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047724</td>\n",
       "      <td>-0.877636</td>\n",
       "      <td>-0.645254</td>\n",
       "      <td>-0.519918</td>\n",
       "      <td>-0.447089</td>\n",
       "      <td>-0.383278</td>\n",
       "      <td>0.703308</td>\n",
       "      <td>0.467238</td>\n",
       "      <td>0.107450</td>\n",
       "      <td>-0.832933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.610657</td>\n",
       "      <td>-0.673046</td>\n",
       "      <td>-0.161636</td>\n",
       "      <td>-0.522966</td>\n",
       "      <td>-0.377196</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>0.800351</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.363954</td>\n",
       "      <td>-0.961244</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047724</td>\n",
       "      <td>-0.877636</td>\n",
       "      <td>2.098494</td>\n",
       "      <td>0.977760</td>\n",
       "      <td>1.960643</td>\n",
       "      <td>-0.296657</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>-0.333328</td>\n",
       "      <td>-0.636876</td>\n",
       "      <td>-0.542584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.053196 -0.219296  0.210020  0.704425  0.339477  0.412638  0.331074   \n",
       "1 -0.632098 -0.682804 -0.285522 -0.369542 -0.138305  2.489725  2.051755   \n",
       "2 -0.674980 -0.597421 -0.568689 -0.983237 -0.828435 -0.496087 -0.451053   \n",
       "3 -0.331927 -0.154649  1.307292  0.090730  0.419107  1.061728  0.956776   \n",
       "4 -0.610657 -0.673046 -0.161636 -0.522966 -0.377196  0.672274  0.800351   \n",
       "\n",
       "         7         8         9   ...        65        66        67        68  \\\n",
       "0 -0.034411 -0.184481  0.307345  ...  0.219541  0.539119 -0.645254 -0.519918   \n",
       "1 -0.034411 -0.246906 -0.226797  ...  0.219541 -0.169259 -0.645254  2.475438   \n",
       "2 -0.034411 -0.324938 -0.627405  ... -1.047724 -0.877636 -0.645254 -0.519918   \n",
       "3 -0.034411 -0.301529 -0.360333  ... -1.047724 -0.877636 -0.645254 -0.519918   \n",
       "4 -0.034411 -0.363954 -0.961244  ... -1.047724 -0.877636  2.098494  0.977760   \n",
       "\n",
       "         69        70        71        72        73        74  \n",
       "0 -0.447089  0.554097  0.087285 -0.109193 -0.913639 -0.461479  \n",
       "1 -0.447089 -0.288927 -0.035919 -1.481978 -1.087664 -0.461479  \n",
       "2 -0.447089 -0.375320 -0.159124  0.349947  0.134707 -0.809315  \n",
       "3 -0.447089 -0.383278  0.703308  0.467238  0.107450 -0.832933  \n",
       "4  1.960643 -0.296657  0.087285 -0.333328 -0.636876 -0.542584  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.8359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.9041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.2065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  5.8359\n",
       "1  6.2592\n",
       "2  6.9041\n",
       "3  6.2065\n",
       "4  7.0642"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459140.0</td>\n",
       "      <td>7524200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461590.0</td>\n",
       "      <td>7549000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462040.0</td>\n",
       "      <td>7549300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>462040.0</td>\n",
       "      <td>7549300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462130.0</td>\n",
       "      <td>7549400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1\n",
       "0  459140.0  7524200.0\n",
       "1  461590.0  7549000.0\n",
       "2  462040.0  7549300.0\n",
       "3  462040.0  7549300.0\n",
       "4  462130.0  7549400.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In this cell, read the files input.csv, output.csv and coordinates.csv.\n",
    "# Print out the dataset dimesions (i.e. number of rows and columns).\n",
    "#\n",
    "# Note that the coordinates are in EUREF-TM35FIN format, so you \n",
    "# can use the Euclidean distance to calculate the distance between two coordinate points.  \n",
    "\n",
    "input_data = pd.read_csv('./input.csv', header=None)  \n",
    "input_df = pd.DataFrame(input_data)\n",
    "print(input_df.shape)\n",
    "display(input_df.head())\n",
    "\n",
    "output_data = pd.read_csv('./output.csv', header=None)  \n",
    "output_df = pd.DataFrame(output_data)\n",
    "print(output_df.shape)\n",
    "display(output_df.head())\n",
    "\n",
    "coordinates_data = pd.read_csv('./coordinates.csv', header=None)  \n",
    "coordinates_df = pd.DataFrame(coordinates_data)\n",
    "print(coordinates_df.shape)\n",
    "display(coordinates_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization of the predictor features (input.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.053196</td>\n",
       "      <td>-0.219296</td>\n",
       "      <td>0.210020</td>\n",
       "      <td>0.704425</td>\n",
       "      <td>0.339477</td>\n",
       "      <td>0.412638</td>\n",
       "      <td>0.331074</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.184481</td>\n",
       "      <td>0.307345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219541</td>\n",
       "      <td>0.539119</td>\n",
       "      <td>-0.645254</td>\n",
       "      <td>-0.519918</td>\n",
       "      <td>-0.447089</td>\n",
       "      <td>0.554097</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>-0.109193</td>\n",
       "      <td>-0.913639</td>\n",
       "      <td>-0.461479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.632098</td>\n",
       "      <td>-0.682804</td>\n",
       "      <td>-0.285522</td>\n",
       "      <td>-0.369542</td>\n",
       "      <td>-0.138305</td>\n",
       "      <td>2.489725</td>\n",
       "      <td>2.051755</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.246906</td>\n",
       "      <td>-0.226797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219541</td>\n",
       "      <td>-0.169259</td>\n",
       "      <td>-0.645254</td>\n",
       "      <td>2.475438</td>\n",
       "      <td>-0.447089</td>\n",
       "      <td>-0.288927</td>\n",
       "      <td>-0.035919</td>\n",
       "      <td>-1.481978</td>\n",
       "      <td>-1.087664</td>\n",
       "      <td>-0.461479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.674980</td>\n",
       "      <td>-0.597421</td>\n",
       "      <td>-0.568689</td>\n",
       "      <td>-0.983237</td>\n",
       "      <td>-0.828435</td>\n",
       "      <td>-0.496087</td>\n",
       "      <td>-0.451053</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.324938</td>\n",
       "      <td>-0.627405</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047724</td>\n",
       "      <td>-0.877636</td>\n",
       "      <td>-0.645254</td>\n",
       "      <td>-0.519918</td>\n",
       "      <td>-0.447089</td>\n",
       "      <td>-0.375320</td>\n",
       "      <td>-0.159124</td>\n",
       "      <td>0.349947</td>\n",
       "      <td>0.134707</td>\n",
       "      <td>-0.809315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.331927</td>\n",
       "      <td>-0.154649</td>\n",
       "      <td>1.307292</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.419107</td>\n",
       "      <td>1.061728</td>\n",
       "      <td>0.956776</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.301529</td>\n",
       "      <td>-0.360333</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047724</td>\n",
       "      <td>-0.877636</td>\n",
       "      <td>-0.645254</td>\n",
       "      <td>-0.519918</td>\n",
       "      <td>-0.447089</td>\n",
       "      <td>-0.383278</td>\n",
       "      <td>0.703308</td>\n",
       "      <td>0.467238</td>\n",
       "      <td>0.107450</td>\n",
       "      <td>-0.832933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.610657</td>\n",
       "      <td>-0.673046</td>\n",
       "      <td>-0.161636</td>\n",
       "      <td>-0.522966</td>\n",
       "      <td>-0.377196</td>\n",
       "      <td>0.672274</td>\n",
       "      <td>0.800351</td>\n",
       "      <td>-0.034411</td>\n",
       "      <td>-0.363954</td>\n",
       "      <td>-0.961244</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047724</td>\n",
       "      <td>-0.877636</td>\n",
       "      <td>2.098494</td>\n",
       "      <td>0.977760</td>\n",
       "      <td>1.960643</td>\n",
       "      <td>-0.296657</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>-0.333328</td>\n",
       "      <td>-0.636876</td>\n",
       "      <td>-0.542584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.053196 -0.219296  0.210020  0.704425  0.339477  0.412638  0.331074   \n",
       "1 -0.632098 -0.682804 -0.285522 -0.369542 -0.138305  2.489725  2.051755   \n",
       "2 -0.674980 -0.597421 -0.568689 -0.983237 -0.828435 -0.496087 -0.451053   \n",
       "3 -0.331927 -0.154649  1.307292  0.090730  0.419107  1.061728  0.956776   \n",
       "4 -0.610657 -0.673046 -0.161636 -0.522966 -0.377196  0.672274  0.800351   \n",
       "\n",
       "         7         8         9   ...        65        66        67        68  \\\n",
       "0 -0.034411 -0.184481  0.307345  ...  0.219541  0.539119 -0.645254 -0.519918   \n",
       "1 -0.034411 -0.246906 -0.226797  ...  0.219541 -0.169259 -0.645254  2.475438   \n",
       "2 -0.034411 -0.324938 -0.627405  ... -1.047724 -0.877636 -0.645254 -0.519918   \n",
       "3 -0.034411 -0.301529 -0.360333  ... -1.047724 -0.877636 -0.645254 -0.519918   \n",
       "4 -0.034411 -0.363954 -0.961244  ... -1.047724 -0.877636  2.098494  0.977760   \n",
       "\n",
       "         69        70        71        72        73        74  \n",
       "0 -0.447089  0.554097  0.087285 -0.109193 -0.913639 -0.461479  \n",
       "1 -0.447089 -0.288927 -0.035919 -1.481978 -1.087664 -0.461479  \n",
       "2 -0.447089 -0.375320 -0.159124  0.349947  0.134707 -0.809315  \n",
       "3 -0.447089 -0.383278  0.703308  0.467238  0.107450 -0.832933  \n",
       "4  1.960643 -0.296657  0.087285 -0.333328 -0.636876 -0.542584  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.053181</td>\n",
       "      <td>-0.219231</td>\n",
       "      <td>0.209958</td>\n",
       "      <td>0.704217</td>\n",
       "      <td>0.339376</td>\n",
       "      <td>0.412516</td>\n",
       "      <td>0.330976</td>\n",
       "      <td>-0.034401</td>\n",
       "      <td>-0.184426</td>\n",
       "      <td>0.307254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219476</td>\n",
       "      <td>0.538960</td>\n",
       "      <td>-0.645063</td>\n",
       "      <td>-0.519764</td>\n",
       "      <td>-0.446957</td>\n",
       "      <td>0.553933</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>-0.109161</td>\n",
       "      <td>-0.913369</td>\n",
       "      <td>-0.461343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.631911</td>\n",
       "      <td>-0.682602</td>\n",
       "      <td>-0.285437</td>\n",
       "      <td>-0.369433</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>2.488989</td>\n",
       "      <td>2.051148</td>\n",
       "      <td>-0.034401</td>\n",
       "      <td>-0.246833</td>\n",
       "      <td>-0.226730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219476</td>\n",
       "      <td>-0.169209</td>\n",
       "      <td>-0.645063</td>\n",
       "      <td>2.474706</td>\n",
       "      <td>-0.446957</td>\n",
       "      <td>-0.288841</td>\n",
       "      <td>-0.035909</td>\n",
       "      <td>-1.481540</td>\n",
       "      <td>-1.087343</td>\n",
       "      <td>-0.461343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.674780</td>\n",
       "      <td>-0.597244</td>\n",
       "      <td>-0.568521</td>\n",
       "      <td>-0.982946</td>\n",
       "      <td>-0.828190</td>\n",
       "      <td>-0.495940</td>\n",
       "      <td>-0.450920</td>\n",
       "      <td>-0.034401</td>\n",
       "      <td>-0.324842</td>\n",
       "      <td>-0.627219</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047414</td>\n",
       "      <td>-0.877377</td>\n",
       "      <td>-0.645063</td>\n",
       "      <td>-0.519764</td>\n",
       "      <td>-0.446957</td>\n",
       "      <td>-0.375210</td>\n",
       "      <td>-0.159077</td>\n",
       "      <td>0.349843</td>\n",
       "      <td>0.134667</td>\n",
       "      <td>-0.809076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.331829</td>\n",
       "      <td>-0.154603</td>\n",
       "      <td>1.306906</td>\n",
       "      <td>0.090703</td>\n",
       "      <td>0.418983</td>\n",
       "      <td>1.061414</td>\n",
       "      <td>0.956493</td>\n",
       "      <td>-0.034401</td>\n",
       "      <td>-0.301439</td>\n",
       "      <td>-0.360227</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047414</td>\n",
       "      <td>-0.877377</td>\n",
       "      <td>-0.645063</td>\n",
       "      <td>-0.519764</td>\n",
       "      <td>-0.446957</td>\n",
       "      <td>-0.383164</td>\n",
       "      <td>0.703100</td>\n",
       "      <td>0.467100</td>\n",
       "      <td>0.107418</td>\n",
       "      <td>-0.832687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.610477</td>\n",
       "      <td>-0.672847</td>\n",
       "      <td>-0.161588</td>\n",
       "      <td>-0.522811</td>\n",
       "      <td>-0.377085</td>\n",
       "      <td>0.672075</td>\n",
       "      <td>0.800114</td>\n",
       "      <td>-0.034401</td>\n",
       "      <td>-0.363847</td>\n",
       "      <td>-0.960959</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047414</td>\n",
       "      <td>-0.877377</td>\n",
       "      <td>2.097873</td>\n",
       "      <td>0.977471</td>\n",
       "      <td>1.960064</td>\n",
       "      <td>-0.296569</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>-0.333230</td>\n",
       "      <td>-0.636687</td>\n",
       "      <td>-0.542423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.053181 -0.219231  0.209958  0.704217  0.339376  0.412516  0.330976   \n",
       "1 -0.631911 -0.682602 -0.285437 -0.369433 -0.138264  2.488989  2.051148   \n",
       "2 -0.674780 -0.597244 -0.568521 -0.982946 -0.828190 -0.495940 -0.450920   \n",
       "3 -0.331829 -0.154603  1.306906  0.090703  0.418983  1.061414  0.956493   \n",
       "4 -0.610477 -0.672847 -0.161588 -0.522811 -0.377085  0.672075  0.800114   \n",
       "\n",
       "         7         8         9   ...        65        66        67        68  \\\n",
       "0 -0.034401 -0.184426  0.307254  ...  0.219476  0.538960 -0.645063 -0.519764   \n",
       "1 -0.034401 -0.246833 -0.226730  ...  0.219476 -0.169209 -0.645063  2.474706   \n",
       "2 -0.034401 -0.324842 -0.627219  ... -1.047414 -0.877377 -0.645063 -0.519764   \n",
       "3 -0.034401 -0.301439 -0.360227  ... -1.047414 -0.877377 -0.645063 -0.519764   \n",
       "4 -0.034401 -0.363847 -0.960959  ... -1.047414 -0.877377  2.097873  0.977471   \n",
       "\n",
       "         69        70        71        72        73        74  \n",
       "0 -0.446957  0.553933  0.087259 -0.109161 -0.913369 -0.461343  \n",
       "1 -0.446957 -0.288841 -0.035909 -1.481540 -1.087343 -0.461343  \n",
       "2 -0.446957 -0.375210 -0.159077  0.349843  0.134667 -0.809076  \n",
       "3 -0.446957 -0.383164  0.703100  0.467100  0.107418 -0.832687  \n",
       "4  1.960064 -0.296569  0.087259 -0.333230 -0.636687 -0.542423  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard diviation of original data 0     1.000296\n",
      "1     1.000296\n",
      "2     1.000296\n",
      "3     1.000296\n",
      "4     1.000296\n",
      "        ...   \n",
      "70    1.000296\n",
      "71    1.000296\n",
      "72    1.000296\n",
      "73    1.000296\n",
      "74    1.000296\n",
      "Length: 75, dtype: float64\n",
      "Mean of original data 0     1.344611e-16\n",
      "1     1.008458e-16\n",
      "2     3.361527e-17\n",
      "3     4.201909e-17\n",
      "4    -1.764802e-16\n",
      "          ...     \n",
      "70   -8.336587e-15\n",
      "71    1.008458e-16\n",
      "72   -1.512687e-16\n",
      "73    1.832032e-15\n",
      "74    3.277489e-16\n",
      "Length: 75, dtype: float64\n",
      "0     1.0\n",
      "1     1.0\n",
      "2     1.0\n",
      "3     1.0\n",
      "4     1.0\n",
      "     ... \n",
      "70    1.0\n",
      "71    1.0\n",
      "72    1.0\n",
      "73    1.0\n",
      "74    1.0\n",
      "Length: 75, dtype: float64\n",
      "0    -3.361527e-17\n",
      "1     0.000000e+00\n",
      "2     5.042290e-17\n",
      "3    -5.882672e-17\n",
      "4     2.100954e-17\n",
      "          ...     \n",
      "70    0.000000e+00\n",
      "71   -8.403817e-18\n",
      "72    1.680763e-17\n",
      "73   -1.680763e-17\n",
      "74    8.403817e-18\n",
      "Length: 75, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Standardize the predictor features (input.csv) by removing the mean and scaling to unit variance. \n",
    "# In other words, z-score the predictor features. You are allowed to use third-party libraries for doing this. \n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "#scale\n",
    "scaler = StandardScaler()\n",
    "scale = scaler.fit_transform(input_df) \n",
    "\n",
    "#back to dataframe \n",
    "input_scaled = pd.DataFrame(scale)\n",
    "\n",
    "#display the dataframe we got with scipys method\n",
    "display(input_scaled.head())\n",
    "\n",
    "# scaling with scipys method doesn't seem to have any affect. I guess it's because the standard diviation is so close to 1 and mean to 0\n",
    "\n",
    "#####################################################################\n",
    "# scale manually \n",
    "input_scaled_m = (input_df - input_df.mean()) / input_df.std()\n",
    "display(input_scaled_m.head())\n",
    "\n",
    "####################################################################\n",
    "print('Standard diviation of original data', input_df.std())\n",
    "print('Mean of original data', input_df.mean())\n",
    "print(input_scaled_m.std())\n",
    "print(input_scaled_m.mean())\n",
    "\n",
    "# Scaling by hand had more of and effect so i'll be using a dataframe made with scaling by hand -> input_scaled_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include here all the functions (for example the C-index-function) that you need in order to implement the task.\n",
    "# taken from first week's assignment\n",
    "def cindex(true_labels, pred_labels):\n",
    "    n = 0\n",
    "    h_num = 0 \n",
    "    for i in range(0, len(true_labels)):\n",
    "        t = true_labels[i]\n",
    "        p = pred_labels[i]\n",
    "        for j in range(i+1, len(true_labels)):\n",
    "            nt = true_labels[j]\n",
    "            np = pred_labels[j]\n",
    "            if (t != nt): \n",
    "                n = n + 1\n",
    "                if (p < np and t < nt) or (p > np and t > nt): \n",
    "                    h_num += 1\n",
    "                elif (p == np):\n",
    "                    h_num += 0.5\n",
    "    cindx =  h_num/n\n",
    "    return cindx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test/train splits for leave-one-out\n",
    "def loo_split(feature_df, label_df, row): \n",
    "\n",
    "        #separate a row from features to use as test set\n",
    "        test_features = feature_df.iloc[[row]]\n",
    "\n",
    "        #drop the testing row from the training set\n",
    "        train_features = feature_df.drop([row], axis=0)\n",
    "        \n",
    "        #separate a row from labels to use as test labels\n",
    "        test_labels = label_df.iloc[[row]]\n",
    "\n",
    "        #drop the testing row from the training labels set\n",
    "        train_labels = label_df.drop([row], axis=0)\n",
    "        \n",
    "        return test_features, train_features, test_labels, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistance(current_sample, compared_sample):\n",
    "    \n",
    "    x1 = coordinates_df.iloc[current_sample][0]\n",
    "    y1 = coordinates_df.iloc[current_sample][1]\n",
    "    \n",
    "    x2 = coordinates_df.iloc[compared_sample][0]\n",
    "    y2 = coordinates_df.iloc[compared_sample][1]\n",
    "    \n",
    "    return math.sqrt( (x2-x1)**2 + (y2-y1)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance \n",
    "def dropClosest(sample, d):\n",
    "    \n",
    "    features = input_scaled_m.copy()\n",
    "    labels = output_df.copy()\n",
    "    \n",
    "    for i in range(input_df.shape[0]):\n",
    "        \n",
    "        if i == sample:\n",
    "            continue\n",
    "        \n",
    "        dist = getDistance(sample, i)\n",
    "        \n",
    "        if dist < d:\n",
    "            \n",
    "            features = features.drop(i, axis = 0)\n",
    "            \n",
    "            labels = labels.drop(i, axis = 0)\n",
    "      \n",
    "    features.reset_index(inplace=True)\n",
    "    labels.reset_index(inplace=True)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c_index for predictions\n",
    "def loo_predictions():\n",
    "    \n",
    "    items = input_scaled_m.shape[0]\n",
    "    \n",
    "    cols = ['prediction_' + str(i) for i in range(0, 251, 10)]\n",
    "    predictions_df = pd.DataFrame(columns=cols, index=range(items))\n",
    "    \n",
    "    #loop trough all samples\n",
    "    for sample in tqdm(range(0, items), total = items, desc =\"Progress: \"):\n",
    "        \n",
    "        predictions = []\n",
    "        for d in range(0, 251, 10):\n",
    "\n",
    "            features, labels = dropClosest(sample, d)\n",
    "        \n",
    "            row_no = np.where(features['index'] == sample)[0][0]\n",
    "        \n",
    "            #make split\n",
    "            test_features, train_features, test_labels, train_labels = loo_split(features, labels, row_no)\n",
    "\n",
    "            # k-nn with 5 neigbours\n",
    "            model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "            # Train the model using the training sets\n",
    "            model.fit(train_features, train_labels)\n",
    "\n",
    "            #Predict Output\n",
    "            predicted = model.predict(test_features)\n",
    "            \n",
    "            col = 'prediction_' + str(d)\n",
    "            predictions_df[col][sample] = predicted[0][1]\n",
    "    \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for spatial leave-one-out cross-validation with 5-nearest neighbor regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start,  2023-02-12 14:35:50.658082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████████████████████████████████████████████████████████████| 1691/1691 [4:49:06<00:00, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done,  2023-02-12 19:24:56.712012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# In this cell, run your script for the Spatial leave-One-Out cross-validation \n",
    "# with 5-nearest neighbor regression model and visualize the results as \n",
    "print('start, ', datetime.now())\n",
    "pred_df = loo_predictions()\n",
    "print('done, ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_0</th>\n",
       "      <th>prediction_10</th>\n",
       "      <th>prediction_20</th>\n",
       "      <th>prediction_30</th>\n",
       "      <th>prediction_40</th>\n",
       "      <th>prediction_50</th>\n",
       "      <th>prediction_60</th>\n",
       "      <th>prediction_70</th>\n",
       "      <th>prediction_80</th>\n",
       "      <th>prediction_90</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction_160</th>\n",
       "      <th>prediction_170</th>\n",
       "      <th>prediction_180</th>\n",
       "      <th>prediction_190</th>\n",
       "      <th>prediction_200</th>\n",
       "      <th>prediction_210</th>\n",
       "      <th>prediction_220</th>\n",
       "      <th>prediction_230</th>\n",
       "      <th>prediction_240</th>\n",
       "      <th>prediction_250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "      <td>6.65086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "      <td>6.5662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.43722</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>6.46074</td>\n",
       "      <td>...</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "      <td>6.43164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.57674</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>6.57966</td>\n",
       "      <td>...</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "      <td>6.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>6.50284</td>\n",
       "      <td>...</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "      <td>6.58452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "      <td>5.2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>...</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "      <td>5.18824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "      <td>5.7487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>5.05734</td>\n",
       "      <td>...</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "      <td>5.31576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>5.20636</td>\n",
       "      <td>...</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "      <td>4.94208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1691 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction_0 prediction_10 prediction_20 prediction_30 prediction_40  \\\n",
       "0         6.65086       6.65086       6.65086       6.65086       6.65086   \n",
       "1          6.5662        6.5662        6.5662        6.5662        6.5662   \n",
       "2         6.43722       6.46074       6.46074       6.46074       6.46074   \n",
       "3         6.57674       6.57966       6.57966       6.57966       6.57966   \n",
       "4         6.50284       6.50284       6.50284       6.50284       6.50284   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "1686       5.2744        5.2744        5.2744        5.2744        5.2744   \n",
       "1687      5.18824       5.18824       5.18824       5.18824       5.18824   \n",
       "1688       5.7487        5.7487        5.7487        5.7487        5.7487   \n",
       "1689      5.05734       5.05734       5.05734       5.05734       5.05734   \n",
       "1690      5.20636       5.20636       5.20636       5.20636       5.20636   \n",
       "\n",
       "     prediction_50 prediction_60 prediction_70 prediction_80 prediction_90  \\\n",
       "0          6.65086       6.65086       6.65086       6.65086       6.65086   \n",
       "1           6.5662        6.5662        6.5662        6.5662        6.5662   \n",
       "2          6.46074       6.46074       6.46074       6.46074       6.46074   \n",
       "3          6.57966       6.57966       6.57966       6.57966       6.57966   \n",
       "4          6.50284       6.50284       6.50284       6.50284       6.50284   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1686        5.2744        5.2744        5.2744        5.2744        5.2744   \n",
       "1687       5.18824       5.18824       5.18824       5.18824       5.18824   \n",
       "1688        5.7487        5.7487        5.7487        5.7487        5.7487   \n",
       "1689       5.05734       5.05734       5.05734       5.05734       5.05734   \n",
       "1690       5.20636       5.20636       5.20636       5.20636       5.20636   \n",
       "\n",
       "      ... prediction_160 prediction_170 prediction_180 prediction_190  \\\n",
       "0     ...        6.65086        6.65086        6.65086        6.65086   \n",
       "1     ...         6.5662         6.5662         6.5662         6.5662   \n",
       "2     ...        6.43164        6.43164        6.43164        6.43164   \n",
       "3     ...          6.485          6.485          6.485          6.485   \n",
       "4     ...        6.58452        6.58452        6.58452        6.58452   \n",
       "...   ...            ...            ...            ...            ...   \n",
       "1686  ...         5.2744         5.2744         5.2744         5.2744   \n",
       "1687  ...        5.18824        5.18824        5.18824        5.18824   \n",
       "1688  ...         5.7487         5.7487         5.7487         5.7487   \n",
       "1689  ...        5.31576        5.31576        5.31576        5.31576   \n",
       "1690  ...        4.94208        4.94208        4.94208        4.94208   \n",
       "\n",
       "     prediction_200 prediction_210 prediction_220 prediction_230  \\\n",
       "0           6.65086        6.65086        6.65086        6.65086   \n",
       "1            6.5662         6.5662         6.5662         6.5662   \n",
       "2           6.43164        6.43164        6.43164        6.43164   \n",
       "3             6.485          6.485          6.485          6.485   \n",
       "4           6.58452        6.58452        6.58452        6.58452   \n",
       "...             ...            ...            ...            ...   \n",
       "1686         5.2744         5.2744         5.2744         5.2744   \n",
       "1687        5.18824        5.18824        5.18824        5.18824   \n",
       "1688         5.7487         5.7487         5.7487         5.7487   \n",
       "1689        5.31576        5.31576        5.31576        5.31576   \n",
       "1690        4.94208        4.94208        4.94208        4.94208   \n",
       "\n",
       "     prediction_240 prediction_250  \n",
       "0           6.65086        6.65086  \n",
       "1            6.5662         6.5662  \n",
       "2           6.43164        6.43164  \n",
       "3             6.485          6.485  \n",
       "4           6.58452        6.58452  \n",
       "...             ...            ...  \n",
       "1686         5.2744         5.2744  \n",
       "1687        5.18824        5.18824  \n",
       "1688         5.7487         5.7487  \n",
       "1689        5.31576        5.31576  \n",
       "1690        4.94208        4.94208  \n",
       "\n",
       "[1691 rows x 26 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|████████████████████████████████████████████████████████████████████████| 26/26 [03:42<00:00,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c_inds = pd.DataFrame(columns=['drop_distance', 'c_index'])\n",
    "\n",
    "for d in tqdm(range(0, 251, 10), total = 26, desc =\"Progress: \"):\n",
    "    \n",
    "    col = 'prediction_' + str(d)\n",
    "    c_index = cindex(output_df[0], pred_df['prediction_' + str(d)])\n",
    "    row = [d, c_index]\n",
    "    c_inds.loc[len(c_inds.index)] = row\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x197a5157460>]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c_inds['drop_distance'], c_inds['c_index'], '.r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this cell, give a brief commentary on the results, what happens to the prediction performance as the prediction distance increases?\n",
    "\n",
    "The prediction becomes more unsertain as the distance increases. Seesm that after 100 meters the unsertainty increases a lot. I figure that as the distance grows the model hasn't seen data that is close enough to the actual datapoint to make predictions. I would say the best distance for training a model would be somewhere between 50-100 meters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
